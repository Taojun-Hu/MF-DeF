{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===>Load from coat data set<===\n",
      "[train] rating ratio: 0.080000\n",
      "[test]  rating ratio: 0.053333\n",
      "# user: 290, # item: 300\n",
      "[MF] epoch:8, xent:37.39917492866516\n",
      "[-0.04494046 -0.09064704  0.11771674 -0.20835941  0.08493842 -0.07913483\n",
      " -0.04008389  0.0490871 ]\n",
      "[ 0.00905602  0.00475985  0.00721022  0.00338268 -0.00280316  0.00334028\n",
      "  0.00833226 -0.0121702 ]\n",
      "mask proportion (within the original y_train = 1 )\n",
      "20.016565433462176\n",
      "prediction for base model\n",
      "0.6076920935476612\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "np.random.seed(2020)\n",
    "torch.manual_seed(2020)\n",
    "import pdb\n",
    "import scipy.sparse as sps\n",
    "import numpy as np\n",
    "import torch\n",
    "torch.manual_seed(2020)\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from math import sqrt\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1./(1. + np.exp(-x))\n",
    "\n",
    "from dataset import load_data, load_features\n",
    "from matrix_factorization import MF, MF_N_IPS, MF_N_DR_JL, MF_N_MRDR_JL\n",
    "from baselines import MF, MF_IPS, MF_ASIPS, MF_SNIPS, MF_DR, MF_DR_JL, MF_MRDR_JL, MF_BaseModel\n",
    "from models import MLP, MLP_exp, MLP_weibull, MLP_lognormal, MF_IPS_DF, MF_DR_JL_DF\n",
    "\n",
    "from utils import gini_index, ndcg_func, get_user_wise_ctr, rating_mat_to_sample, binarize, shuffle, minU,recall_func, precision_func\n",
    "from utils import ndcg_func_both, ndcg_func_feature, recall_func_both, recall_func_feature, generate_total_sample\n",
    "mse_func = lambda x,y: np.mean((x-y)**2)\n",
    "acc_func = lambda x,y: np.sum(x == y) / len(x)\n",
    "\n",
    "\n",
    "dataset_name = \"coat\"\n",
    "\n",
    "if dataset_name == \"coat\":\n",
    "    train_mat, test_mat = load_data(\"coat\")        \n",
    "    x_train, y_train = rating_mat_to_sample(train_mat)\n",
    "    x_test, y_test = rating_mat_to_sample(test_mat)\n",
    "    num_user = train_mat.shape[0]\n",
    "    num_item = train_mat.shape[1]\n",
    "\n",
    "elif dataset_name == \"yahoo\":\n",
    "    x_train, y_train, x_test, y_test = load_data(\"yahoo\")\n",
    "    x_train, y_train = shuffle(x_train, y_train)\n",
    "    num_user = x_train[:,0].max() + 1\n",
    "    num_item = x_train[:,1].max() + 1\n",
    "\n",
    "print(\"# user: {}, # item: {}\".format(num_user, num_item))\n",
    "# binarize\n",
    "y_train = binarize(y_train)\n",
    "y_test = binarize(y_test)\n",
    "n_train = x_train.shape[0]\n",
    "\n",
    "train_user_ind = x_train[:, 0].astype('int')\n",
    "train_item_ind = x_train[:, 1].astype('int')\n",
    "test_user_ind = x_test[:, 0].astype('int')\n",
    "test_item_ind = x_test[:, 1].astype('int')\n",
    "\n",
    "# recover the complete matrix and retrieve the features\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "mf = MF(num_user, num_item, batch_size=128)\n",
    "mf.to(device)\n",
    "mf.fit(x_train, y_train, \n",
    "    lr=0.05,\n",
    "    lamb=1e-3,\n",
    "    tol=1e-4)\n",
    "\n",
    "x_train_x, u_emb_train, v_emb_train = mf.forward(x_train, True)\n",
    "x_test_x, u_emb_test, v_emb_test = mf.forward(x_test, True)\n",
    "\n",
    "# for the feature set of training dataset and test dataset\n",
    "feature_train = torch.cat([u_emb_train, v_emb_train], axis = 1).detach().cpu()\n",
    "feature_test = torch.cat([u_emb_test, v_emb_test], axis = 1).detach().cpu()\n",
    "\n",
    "# the feature of user and item\n",
    "user_W = mf.W(torch.LongTensor(np.arange(num_user) ).to(device) ).detach().cpu()\n",
    "item_H = mf.H(torch.LongTensor(np.arange(num_item) ).to(device) ).detach().cpu()\n",
    "\n",
    "# L = 5, 20%, 19.66%\n",
    "# L = 6.7, 15%, 15.05%\n",
    "# L = 3.2, 30%, 30.12%\n",
    "# L = 9.7, 10%, 10.02%\n",
    "# L = 3.92, 25%, 24.99%\n",
    "\n",
    "L = 8.5\n",
    "sigmaH = 0.1\n",
    "sigmaB = 0.01\n",
    "\n",
    "num_feature = feature_train.shape[1]\n",
    "identity_p = np.diag(np.ones(num_feature))\n",
    "mean_p = np.zeros(num_feature)\n",
    "\n",
    "W_d = np.random.multivariate_normal(mean_p, sigmaH**2*identity_p)\n",
    "print(W_d)\n",
    "W_b = np.random.multivariate_normal(mean_p, sigmaB**2*identity_p)\n",
    "print(W_b)\n",
    "\n",
    "y_train_mask = np.zeros_like(y_train)\n",
    "e_train = np.zeros_like(y_train, dtype='float')\n",
    "d_train = np.zeros_like(y_train, dtype='float') + 1e5\n",
    "\n",
    "prod = 0\n",
    "for i in range(n_train):\n",
    "\n",
    "    ts_i = np.random.uniform(0, L)\n",
    "    # lambda_i = np.exp( np.dot(W_d, feature_train[i, :]) )\n",
    "    mean_i = np.dot(W_d, feature_train[i, :])\n",
    "    sigma_i = np.exp(np.dot(W_b, feature_train[i, :]))\n",
    "    d_i = np.random.lognormal(mean_i, sigma_i)\n",
    "    # d_i = np.random.exponential(lambda_i)\n",
    "    e_i = L - ts_i\n",
    "    if d_i <= e_i:\n",
    "        y_train_mask[i] = y_train[i]\n",
    "        d_train[i] = d_i\n",
    "    else:\n",
    "        if y_train[i] == 1:\n",
    "            prod += 1\n",
    "        y_train_mask[i] = 0\n",
    "    \n",
    "    e_train[i] = e_i\n",
    "\n",
    "print('mask proportion (within the original y_train = 1 )')\n",
    "print( prod/(sum(y_train) )*100 )\n",
    "\n",
    "test_pred = mf.predict(x_test)\n",
    "mse_mf = mse_func(y_test, test_pred)\n",
    "auc_mf = roc_auc_score(y_test, test_pred)\n",
    "print('prediction for base model')\n",
    "print(auc_mf)\n",
    "\n",
    "ips_idxs = np.arange(len(y_test))\n",
    "np.random.shuffle(ips_idxs)\n",
    "y_ips = y_test[ips_idxs[:int(0.05 * len(ips_idxs))]]\n",
    "\n",
    "feature_test = feature_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MF-IPS-DF] epoch:35, xent:651.7670049667358\n",
      "0.7049275263134696\n",
      "[MF-IPS-DF] epoch:30, xent:652.6689786911011\n",
      "0.7071064927050734\n",
      "[MF-IPS-DF] epoch:26, xent:652.1572017669678\n",
      "0.706957729095958\n",
      "[MF-IPS-DF] epoch:30, xent:653.2065629959106\n",
      "0.7042387092383845\n",
      "[MF-IPS-DF] epoch:26, xent:652.9705400466919\n",
      "0.7055703320318691\n",
      "[MF-IPS-DF] epoch:30, xent:653.1038656234741\n",
      "0.7087952834879547\n",
      "[MF-IPS-DF] epoch:33, xent:653.7771310806274\n",
      "0.7059642317766028\n",
      "[MF-IPS-DF] epoch:32, xent:651.2478771209717\n",
      "0.7083864977160581\n",
      "[MF-IPS-DF] epoch:29, xent:653.6994724273682\n",
      "0.7031807380221612\n",
      "[MF-IPS-DF] epoch:31, xent:652.8343000411987\n",
      "0.706539277072657\n",
      "[MF_IPS_DF] test auc: 0.7061666817460187  sd:  0.0016748140480222068\n",
      "[0.23192456 0.70616668 0.61109024 0.67666972 0.42987895 0.69952475]\n",
      "[0.00032938 0.00167481 0.00695699 0.00442868 0.00890848 0.00591386]\n"
     ]
    }
   ],
   "source": [
    "# for our model\n",
    "# for IPS\n",
    "mf_ips_df_acc = []\n",
    "for repeat in np.arange(10):\n",
    "    mf_ips_df = MF_IPS_DF(num_user, num_item, num_feature, batch_size=128)\n",
    "    mf_ips_df.to(device)\n",
    "    mf_ips_df.fit(x_train, y_train_mask, e_train, d_train, feature_train, y_ips,lr=0.025, lamb=6e-3, lamb1=4e-2, tol=1e-5)\n",
    "    test_pred = mf_ips_df.predict(x_test, feature_test)\n",
    "    mse = mse_func(y_test, test_pred)\n",
    "    auc = roc_auc_score(y_test, test_pred)\n",
    "    ndcg_res = ndcg_func_both(mf_ips_df, x_test, y_test, feature_test)\n",
    "    recall_res = recall_func_both(mf_ips_df, x_test, y_test, feature_test)\n",
    "\n",
    "    print(auc)\n",
    "\n",
    "    mf_ips_df_acc.append([ mse, auc, np.mean(ndcg_res[\"ndcg_5\"]), np.mean(ndcg_res['ndcg_10']), np.mean(recall_res['recall_5']), np.mean(recall_res['recall_10'])   ])\n",
    "\n",
    "mf_ips_df_acc = np.array(mf_ips_df_acc)\n",
    "mf_ips_df_mean = mf_ips_df_acc.mean(0)\n",
    "mf_ips_df_sd = mf_ips_df_acc.std(0)\n",
    "\n",
    "print(\"[MF_IPS_DF] test auc:\", mf_ips_df_mean[1], ' sd: ', mf_ips_df_sd[1])\n",
    "print(mf_ips_df_mean)\n",
    "print(mf_ips_df_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MF-DR-JL-DF] epoch:24, xent:49762075.5625\n",
      "0.7171914861204228\n",
      "[MF-DR-JL-DF] epoch:25, xent:49881155.9375\n",
      "0.7141442970276662\n",
      "[MF-DR-JL-DF] epoch:21, xent:49796349.875\n",
      "0.717637776947769\n",
      "[MF-DR-JL-DF] epoch:19, xent:49917402.5\n",
      "0.7269594264897047\n",
      "[MF-DR-JL-DF] epoch:21, xent:49741937.875\n",
      "0.7247303889158255\n",
      "[MF-DR-JL-DF] epoch:20, xent:49812602.0\n",
      "0.7445659234479287\n",
      "[MF-DR-JL-DF] epoch:25, xent:49866575.5\n",
      "0.7099417009045291\n",
      "[MF-DR-JL-DF] epoch:26, xent:49846659.25\n",
      "0.7282132359593833\n",
      "[MF-DR-JL-DF] epoch:20, xent:49848758.125\n",
      "0.7242955042651368\n",
      "[MF-DR-JL-DF] epoch:22, xent:49812134.125\n",
      "0.7390060889650847\n",
      "[MF_DR_JL_DF] test auc: 0.724668582904345  sd:  0.010258677465356227\n",
      "[0.33745513 0.72466858 0.61756337 0.6929773  0.43372315 0.72411167]\n",
      "[0.00085242 0.01025868 0.0218948  0.01794607 0.01939594 0.01303427]\n"
     ]
    }
   ],
   "source": [
    "# for DR\n",
    "mf_dr_df_acc = []\n",
    "for repeat in np.arange(10):\n",
    "    mf_dr_df = MF_DR_JL_DF(num_user, num_item, num_feature, batch_size=128)\n",
    "    mf_dr_df.to(device)\n",
    "    mf_dr_df.fit(x_train, y_train_mask, e_train, d_train, feature_train, user_W, item_H,  y_ips, lr=0.03, lamb=8e-2, lambv=8e-3, tol=1e-5)\n",
    "    test_pred = mf_dr_df.predict(x_test)\n",
    "    mse = mse_func(y_test, test_pred)\n",
    "    auc = roc_auc_score(y_test, test_pred)\n",
    "    ndcg_res = ndcg_func(mf_dr_df, x_test, y_test)\n",
    "    recall_res = recall_func(mf_dr_df, x_test, y_test)\n",
    "\n",
    "    print(auc)\n",
    "\n",
    "    mf_dr_df_acc.append([ mse, auc, np.mean(ndcg_res[\"ndcg_5\"]), np.mean(ndcg_res['ndcg_10']), np.mean(recall_res['recall_5']), np.mean(recall_res['recall_10'])   ])\n",
    "\n",
    "mf_dr_df_acc = np.array(mf_dr_df_acc)\n",
    "mf_dr_df_mean = mf_dr_df_acc.mean(0)\n",
    "mf_dr_df_sd = mf_dr_df_acc.std(0)\n",
    "\n",
    "print(\"[MF_DR_JL_DF] test auc:\", mf_dr_df_mean[1], ' sd: ', mf_dr_df_sd[1])\n",
    "print(mf_dr_df_mean)\n",
    "print(mf_dr_df_sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLP_weibull] epoch:17, xent:57.05696576833725\n",
      "0.6320995716690678\n",
      "[MLP_weibull] epoch:15, xent:56.97569686174393\n",
      "0.6318922305764411\n",
      "[MLP_weibull] epoch:13, xent:56.977576434612274\n",
      "0.6319568977983372\n",
      "[MLP_weibull] epoch:17, xent:57.01525366306305\n",
      "0.632065739789152\n",
      "[MLP_weibull] epoch:22, xent:56.95767438411713\n",
      "0.6319639541618626\n",
      "[MLP_weibull] epoch:17, xent:56.97996234893799\n",
      "0.6318424493817079\n",
      "[MLP_weibull] epoch:18, xent:56.967029452323914\n",
      "0.6321026648695172\n",
      "[MLP_weibull] epoch:15, xent:57.000570356845856\n",
      "0.6320321012342642\n",
      "[MLP_weibull] epoch:14, xent:56.9975306391716\n",
      "0.6319913096533373\n",
      "[MLP_weibull] epoch:21, xent:56.993410646915436\n",
      "0.6321226740099245\n",
      "[MLP_weibull] test auc: 0.6320069593143611  sd:  8.946533648231673e-05\n",
      "[0.2299329  0.63200696 0.52724817 0.60378234 0.36232001 0.64339875]\n",
      "[1.14968074e-03 8.94653365e-05 1.53149073e-04 3.66054493e-04\n",
      " 2.92991320e-04 5.32966580e-04]\n"
     ]
    }
   ],
   "source": [
    "# for weibull\n",
    "mlp_weibull_acc = []\n",
    "for repeat in np.arange(10):\n",
    "    mlp_weibull = MLP_weibull(num_feature, batch_size=128)\n",
    "    mlp_weibull.to(device)\n",
    "    mlp_weibull.fit(x_train, y_train_mask, e_train, d_train, feature_train, lr=0.05, lamb=1e-5,tol=1e-5)\n",
    "    test_pred = mlp_weibull.predict(feature_test)\n",
    "    mse = mse_func(y_test, test_pred)\n",
    "    auc = roc_auc_score(y_test, test_pred)\n",
    "    ndcg_res = ndcg_func_feature(mlp_weibull, x_test, y_test, feature_test)\n",
    "    recall_res = recall_func_feature(mlp_weibull, x_test, y_test, feature_test)\n",
    "\n",
    "    print(auc)\n",
    "\n",
    "    mlp_weibull_acc.append([ mse, auc, np.mean(ndcg_res[\"ndcg_5\"]), np.mean(ndcg_res['ndcg_10']), np.mean(recall_res['recall_5']), np.mean(recall_res['recall_10'])   ])\n",
    "\n",
    "mlp_weibull_acc = np.array(mlp_weibull_acc)\n",
    "mlp_weibull_mean = mlp_weibull_acc.mean(0)\n",
    "mlp_weibull_sd = mlp_weibull_acc.std(0)\n",
    "\n",
    "print(\"[MLP_weibull] test auc:\", mlp_weibull_mean[1], ' sd: ', mlp_weibull_sd[1])\n",
    "print(mlp_weibull_mean)\n",
    "print(mlp_weibull_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MF-DR] epoch:13, xent:56556.689392089844\n",
      "0.6738932528791896\n",
      "[MF-DR] epoch:14, xent:56626.89373779297\n",
      "0.6763601769001337\n",
      "[MF-DR] epoch:16, xent:56613.96691894531\n",
      "0.666817556851091\n",
      "[MF-DR] epoch:16, xent:56585.284118652344\n",
      "0.665985485930191\n",
      "[MF-DR] epoch:12, xent:56545.10369873047\n",
      "0.6855886437785299\n",
      "[MF-DR] epoch:14, xent:56560.783142089844\n",
      "0.689022869577523\n",
      "[MF-DR] epoch:17, xent:56572.462646484375\n",
      "0.6750039051655674\n",
      "[MF-DR] epoch:16, xent:56631.259521484375\n",
      "0.6823898878637507\n",
      "[MF-DR] epoch:12, xent:56589.59423828125\n",
      "0.6712917746386948\n",
      "[MF-DR] epoch:13, xent:56568.56085205078\n",
      "0.6978692295378992\n",
      "[MF_DR] test auc: 0.6784222783122571  sd:  0.00966587928155964\n",
      "[0.23456159 0.67842228 0.57949714 0.65560372 0.40087553 0.69048795]\n",
      "[0.00036644 0.00966588 0.0127627  0.00967543 0.01496525 0.00815074]\n"
     ]
    }
   ],
   "source": [
    "# for DR\n",
    "mf_dr_acc = []\n",
    "for repeat in np.arange(10):\n",
    "    mf_dr = MF_DR(num_user, num_item, batch_size=128)\n",
    "    mf_dr.to(device)\n",
    "    mf_dr.fit(x_train, y_train_mask, y_ips, lr=0.05, lamb=1e-4,tol=1e-5)\n",
    "    test_pred = mf_dr.predict(x_test)\n",
    "    mse = mse_func(y_test, test_pred)\n",
    "    auc = roc_auc_score(y_test, test_pred)\n",
    "    ndcg_res = ndcg_func(mf_dr, x_test, y_test)\n",
    "    recall_res = recall_func(mf_dr, x_test, y_test)\n",
    "\n",
    "    print(auc)\n",
    "\n",
    "    mf_dr_acc.append([ mse, auc, np.mean(ndcg_res[\"ndcg_5\"]), np.mean(ndcg_res['ndcg_10']), np.mean(recall_res['recall_5']), np.mean(recall_res['recall_10'])   ])\n",
    "\n",
    "mf_dr_acc = np.array(mf_dr_acc)\n",
    "mf_dr_mean = mf_dr_acc.mean(0)\n",
    "mf_dr_sd = mf_dr_acc.std(0)\n",
    "\n",
    "print(\"[MF_DR] test auc:\", mf_dr_mean[1], ' sd: ', mf_dr_sd[1])\n",
    "print(mf_dr_mean)\n",
    "print(mf_dr_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
