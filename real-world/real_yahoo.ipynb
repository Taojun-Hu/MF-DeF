{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===>Load from yahoo data set<===\n",
      "[train] num data: 311704\n",
      "[test]  num data: 54000\n",
      "# user: 15401, # item: 1001\n",
      "[MF] epoch:11, xent:1643.3970547318459\n",
      "[ 0.02036644  0.1544109   0.2018596  -0.01241452  0.11725286 -0.17158336\n",
      "  0.04801624 -0.03370286]\n",
      "mask proportion (within the original y_train = 1 )\n",
      "19.47097722263042\n",
      "prediction for base model\n",
      "0.5759255535982502\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0068, -0.0718, -0.0340,  ..., -0.0014,  0.0090,  0.0275],\n",
       "        [-0.0068, -0.0718, -0.0340,  ...,  0.1090,  0.0541, -0.0475],\n",
       "        [-0.0068, -0.0718, -0.0340,  ..., -0.0063,  0.0038,  0.3300],\n",
       "        ...,\n",
       "        [-0.1236,  0.0763, -0.1319,  ...,  0.0071, -0.1110,  0.1820],\n",
       "        [-0.1236,  0.0763, -0.1319,  ..., -0.1814, -0.1245,  0.4052],\n",
       "        [-0.1236,  0.0763, -0.1319,  ...,  0.0093, -0.0013,  0.0675]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "np.random.seed(2020)\n",
    "torch.manual_seed(2020)\n",
    "import pdb\n",
    "import scipy.sparse as sps\n",
    "import numpy as np\n",
    "import torch\n",
    "torch.manual_seed(2020)\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from math import sqrt\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1./(1. + np.exp(-x))\n",
    "\n",
    "from dataset import load_data, load_features\n",
    "from matrix_factorization import MF, MF_N_IPS, MF_N_DR_JL, MF_N_MRDR_JL\n",
    "from baselines import MF, MF_IPS, MF_ASIPS, MF_SNIPS, MF_DR, MF_DR_JL, MF_MRDR_JL, MF_BaseModel\n",
    "from models import MLP, MLP_exp, MLP_weibull, MLP_lognormal, MF_IPS_DF, MF_DR_JL_DF\n",
    "\n",
    "from utils import gini_index, ndcg_func, get_user_wise_ctr, rating_mat_to_sample, binarize, shuffle, minU,recall_func, precision_func\n",
    "from utils import ndcg_func_both, ndcg_func_feature, recall_func_both, recall_func_feature, generate_total_sample\n",
    "mse_func = lambda x,y: np.mean((x-y)**2)\n",
    "acc_func = lambda x,y: np.sum(x == y) / len(x)\n",
    "\n",
    "\n",
    "dataset_name = \"yahoo\"\n",
    "\n",
    "if dataset_name == \"coat\":\n",
    "    train_mat, test_mat = load_data(\"coat\")        \n",
    "    x_train, y_train = rating_mat_to_sample(train_mat)\n",
    "    x_test, y_test = rating_mat_to_sample(test_mat)\n",
    "    num_user = train_mat.shape[0]\n",
    "    num_item = train_mat.shape[1]\n",
    "\n",
    "elif dataset_name == \"yahoo\":\n",
    "    x_train, y_train, x_test, y_test = load_data(\"yahoo\")\n",
    "    x_train, y_train = shuffle(x_train, y_train)\n",
    "    num_user = x_train[:,0].max() + 1\n",
    "    num_item = x_train[:,1].max() + 1\n",
    "\n",
    "print(\"# user: {}, # item: {}\".format(num_user, num_item))\n",
    "# binarize\n",
    "y_train = binarize(y_train)\n",
    "y_test = binarize(y_test)\n",
    "n_train = x_train.shape[0]\n",
    "\n",
    "train_user_ind = x_train[:, 0].astype('int')\n",
    "train_item_ind = x_train[:, 1].astype('int')\n",
    "test_user_ind = x_test[:, 0].astype('int')\n",
    "test_item_ind = x_test[:, 1].astype('int')\n",
    "\n",
    "# recover the complete matrix and retrieve the features\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "mf = MF(num_user, num_item, batch_size=128)\n",
    "mf.to(device)\n",
    "mf.fit(x_train, y_train, \n",
    "    lr=0.05,\n",
    "    lamb=1e-4,\n",
    "    tol=1e-4)\n",
    "\n",
    "x_train_x, u_emb_train, v_emb_train = mf.forward(x_train, True)\n",
    "x_test_x, u_emb_test, v_emb_test = mf.forward(x_test, True)\n",
    "\n",
    "# for the feature set of training dataset and test dataset\n",
    "feature_train = torch.cat([u_emb_train, v_emb_train], axis = 1).detach().cpu()\n",
    "feature_test = torch.cat([u_emb_test, v_emb_test], axis = 1).detach().cpu()\n",
    "\n",
    "# the feature of user and item\n",
    "user_W = mf.W(torch.LongTensor(np.arange(num_user) ).to(device) ).detach().cpu()\n",
    "item_H = mf.H(torch.LongTensor(np.arange(num_item) ).to(device) ).detach().cpu()\n",
    "\n",
    "L = 5\n",
    "sigmaH = 0.1\n",
    "\n",
    "num_feature = feature_train.shape[1]\n",
    "identity_p = np.diag(np.ones(num_feature))\n",
    "mean_p = np.zeros(num_feature)\n",
    "\n",
    "W_d = np.random.multivariate_normal(mean_p, sigmaH**2*identity_p)\n",
    "print(W_d)\n",
    "\n",
    "y_train_mask = np.zeros_like(y_train)\n",
    "e_train = np.zeros_like(y_train, dtype='float')\n",
    "d_train = np.zeros_like(y_train, dtype='float') + 1e5\n",
    "\n",
    "prod = 0\n",
    "for i in range(n_train):\n",
    "\n",
    "    ts_i = np.random.uniform(0, L)\n",
    "    lambda_i = np.exp( np.dot(W_d, feature_train[i, :]) )\n",
    "    d_i = np.random.exponential(lambda_i)\n",
    "    e_i = L - ts_i\n",
    "    if d_i <= e_i:\n",
    "        y_train_mask[i] = y_train[i]\n",
    "        d_train[i] = d_i\n",
    "    else:\n",
    "        if y_train[i] == 1:\n",
    "            prod += 1\n",
    "        y_train_mask[i] = 0\n",
    "    \n",
    "    e_train[i] = e_i\n",
    "\n",
    "print('mask proportion (within the original y_train = 1 )')\n",
    "print( prod/(sum(y_train) )*100 )\n",
    "\n",
    "test_pred = mf.predict(x_test)\n",
    "mse_mf = mse_func(y_test, test_pred)\n",
    "auc_mf = roc_auc_score(y_test, test_pred)\n",
    "print('prediction for base model')\n",
    "print(auc_mf)\n",
    "\n",
    "ips_idxs = np.arange(len(y_test))\n",
    "np.random.shuffle(ips_idxs)\n",
    "y_ips = y_test[ips_idxs[:int(0.05 * len(ips_idxs))]]\n",
    "\n",
    "feature_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MF-IPS-DF] epoch:29, xent:63078.950622558594\n",
      "0.6739248880454392\n"
     ]
    }
   ],
   "source": [
    "mf_ips_df = MF_IPS_DF(num_user, num_item, num_feature, batch_size=128)\n",
    "mf_ips_df.to(device)\n",
    "mf_ips_df.fit(x_train, y_train_mask, e_train, d_train, feature_train, y_ips,lr=0.015, lamb=1.5e-4, lamb1=8e-3, tol=1e-5)\n",
    "test_pred = mf_ips_df.predict(x_test, feature_test)\n",
    "mse = mse_func(y_test, test_pred)\n",
    "auc = roc_auc_score(y_test, test_pred)\n",
    "ndcg_res = ndcg_func_both(mf_ips_df, x_test, y_test, feature_test)\n",
    "recall_res = recall_func_both(mf_ips_df, x_test, y_test, feature_test)\n",
    "\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MF-DR-JL-DF] epoch:13, xent:5321667677.375\n",
      "0.6229792266826\n"
     ]
    }
   ],
   "source": [
    "mf_dr_df = MF_DR_JL_DF(num_user, num_item, num_feature, batch_size=128)\n",
    "mf_dr_df.to(device)\n",
    "# 8e-3, 6e-3\n",
    "# lambv= \n",
    "mf_dr_df.fit(x_train, y_train_mask, e_train, d_train, feature_train, user_W, item_H, y_ips, lr=0.015, lamb=6e-3, lambv=2e-1, tol=1e-5)\n",
    "test_pred = mf_dr_df.predict(x_test)\n",
    "mse = mse_func(y_test, test_pred)\n",
    "auc = roc_auc_score(y_test, test_pred)\n",
    "ndcg_res = ndcg_func(mf_dr_df, x_test, y_test)\n",
    "recall_res = recall_func(mf_dr_df, x_test, y_test)\n",
    "\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lamb:0.06 lamb1:0.6\n",
      "[MF-DR-JL-DF] epoch:16, xent:5320759164.75\n",
      "0.6314890746745259\n",
      "lamb:0.06 lamb1:0.02\n",
      "[MF-DR-JL-DF] epoch:14, xent:5320506767.25\n",
      "0.6368539775665478\n",
      "lamb:0.06 lamb1:0.06\n",
      "[MF-DR-JL-DF] epoch:7, xent:3613717649.6875\n",
      "0.6620493644337688\n",
      "lamb:0.06 lamb1:0.02\n",
      "[MF-DR-JL-DF] epoch:8, xent:3614514280.1875\n",
      "0.6628358356400945\n",
      "lamb:0.06 lamb1:0.006\n",
      "[MF-DR-JL-DF] epoch:14, xent:5321146017.75\n",
      "0.6268504273879778\n",
      "lamb:0.06 lamb1:0.002\n",
      "[MF-DR-JL-DF] epoch:17, xent:5320604919.875\n",
      "0.6351912624933242\n",
      "lamb:0.06 lamb1:0.0006\n",
      "[MF-DR-JL-DF] epoch:7, xent:3614033244.9375\n",
      "0.6619682909729676\n",
      "lamb:0.06 lamb1:0.0002\n",
      "[MF-DR-JL-DF] epoch:7, xent:3612605802.6875\n",
      "0.6619554304072405\n",
      "lamb:0.02 lamb1:0.6\n",
      "[MF-DR-JL-DF] epoch:13, xent:5321084164.375\n",
      "0.6375817525231275\n",
      "lamb:0.02 lamb1:0.02\n",
      "[MF-DR-JL-DF] epoch:12, xent:5321083722.875\n",
      "0.6267116561356667\n",
      "lamb:0.02 lamb1:0.06\n",
      "[MF-DR-JL-DF] epoch:15, xent:5320715140.875\n",
      "0.6302627956134673\n",
      "lamb:0.02 lamb1:0.02\n",
      "[MF-DR-JL-DF] epoch:8, xent:3617904600.375\n",
      "0.6553467701394451\n",
      "lamb:0.02 lamb1:0.006\n",
      "[MF-DR-JL-DF] epoch:15, xent:5320825107.375\n",
      "0.630938843308452\n",
      "lamb:0.02 lamb1:0.002\n",
      "[MF-DR-JL-DF] epoch:14, xent:5320707626.125\n",
      "0.6371806601994188\n",
      "lamb:0.02 lamb1:0.0006\n",
      "[MF-DR-JL-DF] epoch:12, xent:5321435606.5\n",
      "0.6274556914227097\n",
      "lamb:0.02 lamb1:0.0002\n",
      "[MF-DR-JL-DF] epoch:14, xent:5320360542.375\n",
      "0.6338065954122579\n",
      "lamb:0.006 lamb1:0.6\n",
      "[MF-DR-JL-DF] epoch:14, xent:5321070498.375\n",
      "0.6337743510845169\n",
      "lamb:0.006 lamb1:0.02\n",
      "[MF-DR-JL-DF] epoch:7, xent:3614121175.75\n",
      "0.6614778621522166\n",
      "lamb:0.006 lamb1:0.06\n",
      "[MF-DR-JL-DF] epoch:14, xent:5320596861.125\n",
      "0.6372151960706522\n",
      "lamb:0.006 lamb1:0.02\n",
      "[MF-DR-JL-DF] epoch:16, xent:5320578167.5\n",
      "0.636085463203137\n",
      "lamb:0.006 lamb1:0.006\n",
      "[MF-DR-JL-DF] epoch:7, xent:3613137981.75\n",
      "0.6621986016851407\n",
      "lamb:0.006 lamb1:0.002\n",
      "[MF-DR-JL-DF] epoch:14, xent:5321696047.5\n",
      "0.6252626034222923\n",
      "lamb:0.006 lamb1:0.0006\n",
      "[MF-DR-JL-DF] epoch:11, xent:5320538164.125\n",
      "0.6343219096250716\n",
      "lamb:0.006 lamb1:0.0002\n",
      "[MF-DR-JL-DF] epoch:7, xent:3614903990.5625\n",
      "0.655091224526685\n",
      "lamb:0.002 lamb1:0.6\n",
      "[MF-DR-JL-DF] epoch:7, xent:3614547128.9375\n",
      "0.6573331580283306\n",
      "lamb:0.002 lamb1:0.02\n",
      "[MF-DR-JL-DF] epoch:10, xent:5320395654.0\n",
      "0.6344430610261582\n",
      "lamb:0.002 lamb1:0.06\n",
      "[MF-DR-JL-DF] epoch:7, xent:3600459577.875\n",
      "0.6604036992143967\n",
      "lamb:0.002 lamb1:0.02\n",
      "[MF-DR-JL-DF] epoch:13, xent:5321448241.625\n",
      "0.6359213443987308\n",
      "lamb:0.002 lamb1:0.006\n",
      "[MF-DR-JL-DF] epoch:8, xent:3616332631.5625\n",
      "0.6579348403228135\n",
      "lamb:0.002 lamb1:0.002\n",
      "[MF-DR-JL-DF] epoch:7, xent:3593769957.9375\n",
      "0.6597147524403488\n",
      "lamb:0.002 lamb1:0.0006\n",
      "[MF-DR-JL-DF] epoch:14, xent:5320544388.25\n",
      "0.633480015802561\n",
      "lamb:0.002 lamb1:0.0002\n",
      "[MF-DR-JL-DF] epoch:13, xent:5321322100.125\n",
      "0.6279499773540622\n",
      "lamb:0.0006 lamb1:0.6\n",
      "[MF-DR-JL-DF] epoch:12, xent:5321735056.25\n",
      "0.6269439050314745\n",
      "lamb:0.0006 lamb1:0.02\n",
      "[MF-DR-JL-DF] epoch:7, xent:3616486904.1875\n",
      "0.6582993883048158\n",
      "lamb:0.0006 lamb1:0.06\n",
      "[MF-DR-JL-DF] epoch:16, xent:5320682806.5\n",
      "0.6331669322286353\n",
      "lamb:0.0006 lamb1:0.02\n",
      "[MF-DR-JL-DF] epoch:16, xent:5321155602.875\n",
      "0.6358689181200873\n",
      "lamb:0.0006 lamb1:0.006\n",
      "[MF-DR-JL-DF] epoch:12, xent:5321387960.125\n",
      "0.6299096379505899\n",
      "lamb:0.0006 lamb1:0.002\n",
      "[MF-DR-JL-DF] epoch:12, xent:5321079871.375\n",
      "0.6317441860494224\n",
      "lamb:0.0006 lamb1:0.0006\n",
      "[MF-DR-JL-DF] epoch:7, xent:3597563581.5\n",
      "0.6614158845662426\n",
      "lamb:0.0006 lamb1:0.0002\n",
      "[MF-DR-JL-DF] epoch:8, xent:3613469423.125\n",
      "0.6627210687872849\n",
      "lamb:0.0002 lamb1:0.6\n",
      "[MF-DR-JL-DF] epoch:7, xent:3613120627.4375\n",
      "0.6598777225845086\n",
      "lamb:0.0002 lamb1:0.02\n",
      "[MF-DR-JL-DF] epoch:7, xent:3614072543.375\n",
      "0.6638486776443192\n",
      "lamb:0.0002 lamb1:0.06\n",
      "[MF-DR-JL-DF] epoch:7, xent:3613535263.4375\n",
      "0.6603142712481815\n",
      "lamb:0.0002 lamb1:0.02\n",
      "[MF-DR-JL-DF] epoch:10, xent:5321147294.375\n",
      "0.6300417088452688\n",
      "lamb:0.0002 lamb1:0.006\n",
      "[MF-DR-JL-DF] epoch:10, xent:5321339547.5\n",
      "0.625207110519269\n",
      "lamb:0.0002 lamb1:0.002\n",
      "[MF-DR-JL-DF] epoch:13, xent:5321021808.875\n",
      "0.627159042452093\n",
      "lamb:0.0002 lamb1:0.0006\n",
      "[MF-DR-JL-DF] epoch:17, xent:5321031556.375\n",
      "0.6279445488993516\n",
      "lamb:0.0002 lamb1:0.0002\n",
      "[MF-DR-JL-DF] epoch:12, xent:5320336976.5\n",
      "0.6336752841931319\n"
     ]
    }
   ],
   "source": [
    "for lambv1 in [6e-2, 2e-2, 6e-3, 2e-3, 6e-4, 2e-4]:\n",
    "    for lambv2 in [6e-1, 2e-1, 6e-2, 2e-2, 6e-3, 2e-3, 6e-4, 2e-4]:\n",
    "        print(\"lamb:\" + str(lambv1) + \" lamb1:\"+ str(lambv2))\n",
    "        mf_dr_df = MF_DR_JL_DF(num_user, num_item, num_feature, batch_size=128)\n",
    "        mf_dr_df.to(device)\n",
    "        mf_dr_df.fit(x_train, y_train_mask, e_train, d_train, feature_train, user_W, item_H, y_ips, lr=0.015, lamb=6e-3, lambv=2e-1, tol=1e-5)\n",
    "        test_pred = mf_dr_df.predict(x_test)\n",
    "        mse = mse_func(y_test, test_pred)\n",
    "        auc = roc_auc_score(y_test, test_pred)\n",
    "        ndcg_res = ndcg_func(mf_dr_df, x_test, y_test)\n",
    "        recall_res = recall_func(mf_dr_df, x_test, y_test)\n",
    "\n",
    "        print(auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:0.03\n",
      "[MF-DR-JL-DF] epoch:16, xent:5315956128.25\n",
      "0.5999784529439025\n",
      "lr:0.025\n",
      "[MF-DR-JL-DF] epoch:7, xent:3624968971.125\n",
      "0.6426050710097433\n",
      "lr:0.02\n",
      "[MF-DR-JL-DF] epoch:13, xent:5315591209.5\n",
      "0.6077962384328974\n",
      "lr:0.01\n",
      "[MF-DR-JL-DF] epoch:12, xent:5313943941.875\n",
      "0.6391462990285286\n",
      "lr:0.005\n",
      "[MF-DR-JL-DF] epoch:19, xent:5312144373.625\n",
      "0.6515511460789865\n"
     ]
    }
   ],
   "source": [
    "for lrv in [0.03, 0.025, 0.02, 0.01, 0.005]:\n",
    "    print('lr:'+str(lrv))\n",
    "    mf_dr_df = MF_DR_JL_DF(num_user, num_item, num_feature, batch_size=128)\n",
    "    mf_dr_df.to(device)\n",
    "    mf_dr_df.fit(x_train, y_train_mask, e_train, d_train, feature_train, user_W, item_H, y_ips, lr=lrv, lamb=2e-4, lambv=2e-2, tol=1e-4)\n",
    "    test_pred = mf_dr_df.predict(x_test)\n",
    "    mse = mse_func(y_test, test_pred)\n",
    "    auc = roc_auc_score(y_test, test_pred)\n",
    "    ndcg_res = ndcg_func(mf_dr_df, x_test, y_test)\n",
    "    recall_res = recall_func(mf_dr_df, x_test, y_test)\n",
    "\n",
    "    print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambv1:0.06 lambv2:0.06\n",
      "[MF-DR-JL-DF] epoch:10, xent:5384668484.875\n",
      "0.6344402832517986\n",
      "lambv1:0.06 lambv2:0.0006\n",
      "[MF-DR-JL-DF] epoch:7, xent:3673876509.625\n",
      "0.66660915951617\n",
      "lambv1:0.06 lambv2:0.0002\n",
      "[MF-DR-JL-DF] epoch:7, xent:3692313520.3125\n",
      "0.6645464083474775\n",
      "lambv1:0.006 lambv2:0.02\n",
      "[MF-DR-JL-DF] epoch:7, xent:3615371431.6875\n",
      "0.6607907986802997\n",
      "lambv1:0.006 lambv2:0.006\n",
      "[MF-DR-JL-DF] epoch:8, xent:5320331388.25\n",
      "0.6359330630440453\n",
      "lambv1:0.002 lambv2:0.06\n",
      "[MF-DR-JL-DF] epoch:8, xent:5317055648.125\n",
      "0.6218884500544588\n",
      "lambv1:0.0006 lambv2:0.0006\n",
      "[MF-DR-JL-DF] epoch:10, xent:5313392855.75\n",
      "0.6253327410213334\n",
      "lambv1:0.0006 lambv2:0.0002\n",
      "[MF-DR-JL-DF] epoch:8, xent:3585223869.4375\n",
      "0.6455433968761205\n"
     ]
    }
   ],
   "source": [
    "lambset = [(0.06, 0.06), (0.06, 6e-4), (6e-2, 2e-4), (6e-3, 2e-2), (6e-3, 6e-3), (2e-3, 6e-2), (6e-4, 6e-4), (6e-4, 2e-4)]\n",
    "\n",
    "for lambv1, lambv2 in lambset:\n",
    "    print('lambv1:'+str(lambv1)+ \" lambv2:\"+str(lambv2))\n",
    "    mf_dr_df = MF_DR_JL_DF(num_user, num_item, num_feature, batch_size=128)\n",
    "    mf_dr_df.to(device)\n",
    "    mf_dr_df.fit(x_train, y_train_mask, e_train, d_train, feature_train, user_W, item_H, y_ips, lr=0.015, lamb=lambv1, lambv=lambv2, tol=1e-4)\n",
    "    test_pred = mf_dr_df.predict(x_test)\n",
    "    mse = mse_func(y_test, test_pred)\n",
    "    auc = roc_auc_score(y_test, test_pred)\n",
    "    ndcg_res = ndcg_func(mf_dr_df, x_test, y_test)\n",
    "    recall_res = recall_func(mf_dr_df, x_test, y_test)\n",
    "\n",
    "    print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambv1:0.0075 lambv2:0.03\n",
      "[MF-DR-JL-DF] epoch:12, xent:5322493422.75\n",
      "0.6344357675631513\n",
      "lambv1:0.0075 lambv2:0.02\n",
      "[MF-DR-JL-DF] epoch:10, xent:5322897091.5\n",
      "0.6306801396021391\n",
      "lambv1:0.0075 lambv2:0.01\n",
      "[MF-DR-JL-DF] epoch:11, xent:5322733460.125\n",
      "0.6335998837467249\n",
      "lambv1:0.0075 lambv2:0.008\n",
      "[MF-DR-JL-DF] epoch:15, xent:5322362930.75\n",
      "0.6344041827762896\n",
      "lambv1:0.006 lambv2:0.03\n",
      "[MF-DR-JL-DF] epoch:13, xent:5321130290.625\n",
      "0.6292466828641818\n",
      "lambv1:0.006 lambv2:0.02\n",
      "[MF-DR-JL-DF] epoch:16, xent:5320541673.0\n",
      "0.635516525909763\n",
      "lambv1:0.006 lambv2:0.01\n",
      "[MF-DR-JL-DF] epoch:11, xent:5320999086.25\n",
      "0.6264828628489325\n",
      "lambv1:0.006 lambv2:0.008\n",
      "[MF-DR-JL-DF] epoch:15, xent:5321750199.875\n",
      "0.625712944674424\n",
      "lambv1:0.0045 lambv2:0.03\n",
      "[MF-DR-JL-DF] epoch:7, xent:3609524166.625\n",
      "0.6622179613763194\n",
      "lambv1:0.0045 lambv2:0.02\n",
      "[MF-DR-JL-DF] epoch:7, xent:3609731066.8125\n",
      "0.6583781471141228\n",
      "lambv1:0.0045 lambv2:0.01\n",
      "[MF-DR-JL-DF] epoch:7, xent:3593270124.75\n",
      "0.659372207127209\n",
      "lambv1:0.0045 lambv2:0.008\n",
      "[MF-DR-JL-DF] epoch:12, xent:5319615936.25\n",
      "0.620583303383919\n",
      "lambv1:0.003 lambv2:0.03\n",
      "[MF-DR-JL-DF] epoch:12, xent:5316556032.25\n",
      "0.6294154723734124\n",
      "lambv1:0.003 lambv2:0.02\n",
      "[MF-DR-JL-DF] epoch:7, xent:3599619320.375\n",
      "0.6566361677440571\n",
      "lambv1:0.003 lambv2:0.01\n",
      "[MF-DR-JL-DF] epoch:8, xent:3602370025.875\n",
      "0.6561318789365095\n",
      "lambv1:0.003 lambv2:0.008\n",
      "[MF-DR-JL-DF] epoch:11, xent:5316899134.875\n",
      "0.629119853634534\n"
     ]
    }
   ],
   "source": [
    "# lambset = [(0.06, 6e-4), (6e-2, 2e-4), (6e-3, 2e-2)]\n",
    "lambset = [(u, v) for u in ( 7.5e-3, 6e-3, 4.5e-3, 3e-3) for v in (3e-2, 2e-2, 1e-2, 8e-3)]\n",
    "# the last one is of the best?\n",
    "\n",
    "for lambv1, lambv2 in lambset:\n",
    "    print('lambv1:'+str(lambv1)+ \" lambv2:\"+str(lambv2))\n",
    "    mf_dr_df = MF_DR_JL_DF(num_user, num_item, num_feature, batch_size=256)\n",
    "    mf_dr_df.to(device)\n",
    "    mf_dr_df.fit(x_train, y_train_mask, e_train, d_train, feature_train, user_W, item_H, y_ips, lr=0.015, lamb=lambv1, lambv=lambv2, tol=1e-5)\n",
    "    test_pred = mf_dr_df.predict(x_test)\n",
    "    mse = mse_func(y_test, test_pred)\n",
    "    auc = roc_auc_score(y_test, test_pred)\n",
    "    ndcg_res = ndcg_func(mf_dr_df, x_test, y_test)\n",
    "    recall_res = recall_func(mf_dr_df, x_test, y_test)\n",
    "\n",
    "    print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambv1:0.0075 lambv2:0.03\n",
      "[MF-DR-JL-DF] epoch:8, xent:5322979131.5\n",
      "0.6303783491011649\n",
      "lambv1:0.0075 lambv2:0.02\n",
      "[MF-DR-JL-DF] epoch:7, xent:3617225682.375\n",
      "0.667123964390115\n",
      "lambv1:0.0075 lambv2:0.01\n",
      "[MF-DR-JL-DF] epoch:9, xent:5322828581.875\n",
      "0.6282789380507579\n",
      "lambv1:0.0075 lambv2:0.008\n",
      "[MF-DR-JL-DF] epoch:8, xent:5322611986.625\n",
      "0.6314106499684088\n",
      "lambv1:0.006 lambv2:0.03\n",
      "[MF-DR-JL-DF] epoch:8, xent:5321731537.375\n",
      "0.6276359251697359\n",
      "lambv1:0.006 lambv2:0.02\n",
      "[MF-DR-JL-DF] epoch:8, xent:5321120277.25\n",
      "0.6291633043802205\n",
      "lambv1:0.006 lambv2:0.01\n",
      "[MF-DR-JL-DF] epoch:8, xent:5321319959.125\n",
      "0.636918671305544\n",
      "lambv1:0.006 lambv2:0.008\n",
      "[MF-DR-JL-DF] epoch:8, xent:5320899502.25\n",
      "0.6309977802665481\n",
      "lambv1:0.0045 lambv2:0.03\n",
      "[MF-DR-JL-DF] epoch:8, xent:5318768994.875\n",
      "0.6318186862466002\n",
      "lambv1:0.0045 lambv2:0.02\n",
      "[MF-DR-JL-DF] epoch:7, xent:3609608158.0625\n",
      "0.6564440728523733\n",
      "lambv1:0.0045 lambv2:0.01\n",
      "[MF-DR-JL-DF] epoch:8, xent:5319435024.625\n",
      "0.6236498776963761\n",
      "lambv1:0.0045 lambv2:0.008\n",
      "[MF-DR-JL-DF] epoch:8, xent:5319816182.375\n",
      "0.6215080952365245\n",
      "lambv1:0.003 lambv2:0.03\n",
      "[MF-DR-JL-DF] epoch:8, xent:5317552639.125\n",
      "0.6277781616594544\n",
      "lambv1:0.003 lambv2:0.02\n",
      "[MF-DR-JL-DF] epoch:8, xent:5317294315.5\n",
      "0.6197777709647687\n",
      "lambv1:0.003 lambv2:0.01\n",
      "[MF-DR-JL-DF] epoch:7, xent:3603705013.75\n",
      "0.6554801851495508\n",
      "lambv1:0.003 lambv2:0.008\n",
      "[MF-DR-JL-DF] epoch:8, xent:5316898392.75\n",
      "0.6264658784677521\n"
     ]
    }
   ],
   "source": [
    "# lambset = [(0.06, 6e-4), (6e-2, 2e-4), (6e-3, 2e-2)]\n",
    "lambset = [(u, v) for u in ( 7.5e-3, 6e-3, 4.5e-3, 3e-3) for v in (3e-2, 2e-2, 1e-2, 8e-3)]\n",
    "# the last one is of the best?\n",
    "\n",
    "for lambv1, lambv2 in lambset:\n",
    "    print('lambv1:'+str(lambv1)+ \" lambv2:\"+str(lambv2))\n",
    "    mf_dr_df = MF_DR_JL_DF(num_user, num_item, num_feature, batch_size=256)\n",
    "    mf_dr_df.to(device)\n",
    "    mf_dr_df.fit(x_train, y_train_mask, e_train, d_train, feature_train, user_W, item_H, y_ips, lr=0.015, lamb=lambv1, lambv=lambv2, tol=1e-4)\n",
    "    test_pred = mf_dr_df.predict(x_test)\n",
    "    mse = mse_func(y_test, test_pred)\n",
    "    auc = roc_auc_score(y_test, test_pred)\n",
    "    ndcg_res = ndcg_func(mf_dr_df, x_test, y_test)\n",
    "    recall_res = recall_func(mf_dr_df, x_test, y_test)\n",
    "\n",
    "    print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MF-DR-JL-DF] epoch:8, xent:5313381131.875\n",
      "0.6207252741316192\n"
     ]
    }
   ],
   "source": [
    "mf_dr_df = MF_DR_JL_DF(num_user, num_item, num_feature, batch_size=256)\n",
    "mf_dr_df.to(device)\n",
    "mf_dr_df.fit(x_train, y_train_mask, e_train, d_train, feature_train, user_W, item_H, y_ips, lr=0.015, lamb=7.5e-4, lambv=2e-2, tol=1e-4)\n",
    "test_pred = mf_dr_df.predict(x_test)\n",
    "mse = mse_func(y_test, test_pred)\n",
    "auc = roc_auc_score(y_test, test_pred)\n",
    "ndcg_res = ndcg_func(mf_dr_df, x_test, y_test)\n",
    "recall_res = recall_func(mf_dr_df, x_test, y_test)\n",
    "\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MF-DR-JL-DF] epoch:8, xent:3569307049.6875\n",
      "0.6474591946342666\n"
     ]
    }
   ],
   "source": [
    "    mf_dr_df = MF_DR_JL_DF(num_user, num_item, num_feature, batch_size=256)\n",
    "    mf_dr_df.to(device)\n",
    "    mf_dr_df.fit(x_train, y_train_mask, e_train, d_train, feature_train, user_W, item_H, y_ips, lr=0.015, lamb=3e-4, lambv=0.01, tol=1e-4)\n",
    "    test_pred = mf_dr_df.predict(x_test)\n",
    "    mse = mse_func(y_test, test_pred)\n",
    "    auc = roc_auc_score(y_test, test_pred)\n",
    "    ndcg_res = ndcg_func(mf_dr_df, x_test, y_test)\n",
    "    recall_res = recall_func(mf_dr_df, x_test, y_test)\n",
    "\n",
    "    print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MF-DR-JL-DF] epoch:9, xent:5313960247.5\n",
      "0.6188618699157811\n",
      "[MF-DR-JL-DF] epoch:9, xent:5314617508.875\n",
      "0.6221679365197161\n",
      "[MF-DR-JL-DF] epoch:9, xent:3584543424.1875\n",
      "0.6461446622637412\n"
     ]
    }
   ],
   "source": [
    "mf_dr_df = MF_DR_JL_DF(num_user, num_item, num_feature, batch_size=256)\n",
    "mf_dr_df.to(device)\n",
    "mf_dr_df.fit(x_train, y_train_mask, e_train, d_train, feature_train, user_W, item_H, y_ips, lr=0.015, lamb=4.5e-4, lambv=0.03, tol=1e-4)\n",
    "test_pred = mf_dr_df.predict(x_test)\n",
    "mse = mse_func(y_test, test_pred)\n",
    "auc = roc_auc_score(y_test, test_pred)\n",
    "ndcg_res = ndcg_func(mf_dr_df, x_test, y_test)\n",
    "recall_res = recall_func(mf_dr_df, x_test, y_test)\n",
    "\n",
    "print(auc)\n",
    "\n",
    "mf_dr_df = MF_DR_JL_DF(num_user, num_item, num_feature, batch_size=256)\n",
    "mf_dr_df.to(device)\n",
    "mf_dr_df.fit(x_train, y_train_mask, e_train, d_train, feature_train, user_W, item_H, y_ips, lr=0.015, lamb=4.5e-4, lambv=0.02, tol=1e-4)\n",
    "test_pred = mf_dr_df.predict(x_test)\n",
    "mse = mse_func(y_test, test_pred)\n",
    "auc = roc_auc_score(y_test, test_pred)\n",
    "ndcg_res = ndcg_func(mf_dr_df, x_test, y_test)\n",
    "recall_res = recall_func(mf_dr_df, x_test, y_test)\n",
    "\n",
    "print(auc)\n",
    "\n",
    "mf_dr_df = MF_DR_JL_DF(num_user, num_item, num_feature, batch_size=256)\n",
    "mf_dr_df.to(device)\n",
    "mf_dr_df.fit(x_train, y_train_mask, e_train, d_train, feature_train, user_W, item_H, y_ips, lr=0.015, lamb=4.5e-4, lambv=0.01, tol=1e-4)\n",
    "test_pred = mf_dr_df.predict(x_test)\n",
    "mse = mse_func(y_test, test_pred)\n",
    "auc = roc_auc_score(y_test, test_pred)\n",
    "ndcg_res = ndcg_func(mf_dr_df, x_test, y_test)\n",
    "recall_res = recall_func(mf_dr_df, x_test, y_test)\n",
    "\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLP] epoch:13, xent:1631.1103895306587\n",
      "0.5725012895661005\n"
     ]
    }
   ],
   "source": [
    "mlp = MLP(num_feature, batch_size=128)\n",
    "mlp.to(device)\n",
    "mlp.fit(x_train, y_train_mask, feature_train, lr=0.05, lamb=1e-4,tol=1e-5)\n",
    "test_pred = mlp.predict(feature_test)\n",
    "mse = mse_func(y_test, test_pred)\n",
    "auc = roc_auc_score(y_test, test_pred)\n",
    "ndcg_res = ndcg_func_feature(mlp, x_test, y_test, feature_test)\n",
    "recall_res = recall_func_feature(mlp, x_test, y_test, feature_test)\n",
    "\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLP_exp] epoch:11, xent:2128.7732273340225\n",
      "0.5997989316935926\n"
     ]
    }
   ],
   "source": [
    "mlp_exp = MLP_exp(num_feature, batch_size=128)\n",
    "mlp_exp.to(device)\n",
    "mlp_exp.fit(x_train, y_train_mask, e_train, d_train, feature_train, lr=0.05, lamb=1e-4,tol=1e-5)\n",
    "test_pred = mlp_exp.predict(feature_test)\n",
    "mse = mse_func(y_test, test_pred)\n",
    "auc = roc_auc_score(y_test, test_pred)\n",
    "ndcg_res = ndcg_func_feature(mlp_exp, x_test, y_test, feature_test)\n",
    "recall_res = recall_func_feature(mlp_exp, x_test, y_test, feature_test)\n",
    "\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLP_weibull] epoch:14, xent:2131.2197816967964\n",
      "0.5994565596904647\n"
     ]
    }
   ],
   "source": [
    "mlp_weibull = MLP_weibull(num_feature, batch_size=128)\n",
    "mlp_weibull.to(device)\n",
    "mlp_weibull.fit(x_train, y_train_mask, e_train, d_train, feature_train, lr=0.05, lamb=1e-4,tol=1e-5)\n",
    "test_pred = mlp_weibull.predict(feature_test)\n",
    "mse = mse_func(y_test, test_pred)\n",
    "auc = roc_auc_score(y_test, test_pred)\n",
    "ndcg_res = ndcg_func_feature(mlp_weibull, x_test, y_test, feature_test)\n",
    "recall_res = recall_func_feature(mlp_weibull, x_test, y_test, feature_test)\n",
    "\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLP_lognormal] epoch:13, xent:2216.64629137516\n",
      "0.5982261105979498\n"
     ]
    }
   ],
   "source": [
    "mlp_lognormal = MLP_lognormal(num_feature, batch_size=128)\n",
    "mlp_lognormal.to(device)\n",
    "mlp_lognormal.fit(x_train, y_train_mask, e_train, d_train, feature_train, lr=0.05, lamb=1e-4,tol=1e-5)\n",
    "test_pred = mlp_lognormal.predict(feature_test)\n",
    "mse = mse_func(y_test, test_pred)\n",
    "auc = roc_auc_score(y_test, test_pred)\n",
    "ndcg_res = ndcg_func_feature(mlp_lognormal, x_test, y_test, feature_test)\n",
    "recall_res = recall_func_feature(mlp_lognormal, x_test, y_test, feature_test)\n",
    "\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MF] epoch:8, xent:1687.8201692700386\n",
      "0.501736095495157\n"
     ]
    }
   ],
   "source": [
    "mf = MF(num_user, num_item, batch_size=128)\n",
    "mf.to(device)\n",
    "mf.fit(x_train, y_train_mask, lr=0.05, lamb=3e-4,tol=1e-4)\n",
    "test_pred = mf.predict(x_test)\n",
    "mse = mse_func(y_test, test_pred)\n",
    "auc = roc_auc_score(y_test, test_pred)\n",
    "ndcg_res = ndcg_func(mf, x_test, y_test)\n",
    "recall_res = recall_func(mf, x_test, y_test)\n",
    "\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MF-IPS] epoch:20, xent:65258.30628013611\n",
      "0.6042178613610372\n"
     ]
    }
   ],
   "source": [
    "mf_ips = MF_IPS(num_user, num_item, batch_size=128)\n",
    "mf_ips.to(device)\n",
    "mf_ips.fit(x_train, y_train_mask, y_ips, lr=0.05, lamb=8e-4,tol=1e-5)\n",
    "test_pred = mf_ips.predict(x_test)\n",
    "mse = mse_func(y_test, test_pred)\n",
    "auc = roc_auc_score(y_test, test_pred)\n",
    "ndcg_res = ndcg_func(mf_ips, x_test, y_test)\n",
    "recall_res = recall_func(mf_ips, x_test, y_test)\n",
    "\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MF-SNIPS] epoch:20, xent:1580.0672101974487\n",
      "0.5612743132018367\n"
     ]
    }
   ],
   "source": [
    "mf_snips = MF_SNIPS(num_user, num_item, batch_size=128)\n",
    "mf_snips.to(device)\n",
    "mf_snips.fit(x_train, y_train_mask, y_ips, lr=0.05, lamb=1e-4,tol=1e-5)\n",
    "test_pred = mf_snips.predict(x_test)\n",
    "mse = mse_func(y_test, test_pred)\n",
    "auc = roc_auc_score(y_test, test_pred)\n",
    "ndcg_res = ndcg_func(mf_snips, x_test, y_test)\n",
    "recall_res = recall_func(mf_snips, x_test, y_test)\n",
    "\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MF-IPS-Pred1] epoch:23, xent:63851.45141410828\n",
      "[MF-IPS-Pred2] epoch:22, xent:63880.79926490784\n",
      "[MF-ASIPS] epoch:16, xent:1276.1306467056274\n",
      "0.6064912525555356\n"
     ]
    }
   ],
   "source": [
    "mf_asips = MF_ASIPS(num_user, num_item, batch_size=128)\n",
    "mf_asips.to(device)\n",
    "mf_asips.fit(x_train, y_train_mask, y_ips, tao=1e-2, lr=0.05, lamb=5e-5,tol=1e-5,batch_size=128,stop=5)\n",
    "test_pred = mf_asips.predict(x_test)\n",
    "mse = mse_func(y_test, test_pred)\n",
    "auc = roc_auc_score(y_test, test_pred)\n",
    "ndcg_res = ndcg_func(mf_asips, x_test, y_test)\n",
    "recall_res = recall_func(mf_asips, x_test, y_test)\n",
    "\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MF-DR] epoch:12, xent:8011417.116943359\n",
      "0.5899627181086522\n"
     ]
    }
   ],
   "source": [
    "mf_dr = MF_DR(num_user, num_item, batch_size=128)\n",
    "mf_dr.to(device)\n",
    "mf_dr.fit(x_train, y_train_mask, y_ips, lr=0.05, lamb=1e-6,tol=1e-5)\n",
    "test_pred = mf_dr.predict(x_test)\n",
    "mse = mse_func(y_test, test_pred)\n",
    "auc = roc_auc_score(y_test, test_pred)\n",
    "ndcg_res = ndcg_func(mf_dr, x_test, y_test)\n",
    "recall_res = recall_func(mf_dr, x_test, y_test)\n",
    "\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MF-DR-JL] epoch:14, xent:8014958.329833984\n",
      "0.6188025892261613\n"
     ]
    }
   ],
   "source": [
    "mf_dr_jl = MF_DR_JL(num_user, num_item, batch_size=128)\n",
    "mf_dr_jl.to(device)\n",
    "# 0.03 1e-3\n",
    "mf_dr_jl.fit(x_train, y_train_mask, y_ips, lr=0.03, lamb=1e-3,tol=1e-5)\n",
    "test_pred = mf_dr_jl.predict(x_test)\n",
    "mse = mse_func(y_test, test_pred)\n",
    "auc = roc_auc_score(y_test, test_pred)\n",
    "ndcg_res = ndcg_func(mf_dr_jl, x_test, y_test)\n",
    "recall_res = recall_func(mf_dr_jl, x_test, y_test)\n",
    "\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MF-MRDR-JL] epoch:16, xent:8140195.770751953\n",
      "0.6268744606724814\n"
     ]
    }
   ],
   "source": [
    "mf_mrdr = MF_MRDR_JL(num_user, num_item, batch_size=128)\n",
    "mf_mrdr.to(device)\n",
    "mf_mrdr.fit(x_train, y_train_mask, y_ips, lr=0.05, lamb=1e-4,tol=1e-5)\n",
    "test_pred = mf_mrdr.predict(x_test)\n",
    "mse = mse_func(y_test, test_pred)\n",
    "auc = roc_auc_score(y_test, test_pred)\n",
    "ndcg_res = ndcg_func(mf_mrdr, x_test, y_test)\n",
    "recall_res = recall_func(mf_mrdr, x_test, y_test)\n",
    "\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MF-DR-JL-DF] epoch:9, xent:5312941883.0\n",
      "0.6276717454607252\n"
     ]
    }
   ],
   "source": [
    "mf_dr_df = MF_DR_JL_DF(num_user, num_item, num_feature, batch_size=256)\n",
    "mf_dr_df.to(device)\n",
    "mf_dr_df.fit(x_train, y_train_mask, e_train, d_train, feature_train, user_W, item_H, y_ips, lr=0.015, lamb=3e-5, lambv=5e-3, tol=1e-4)\n",
    "test_pred = mf_dr_df.predict(x_test)\n",
    "mse = mse_func(y_test, test_pred)\n",
    "auc = roc_auc_score(y_test, test_pred)\n",
    "ndcg_res = ndcg_func(mf_dr_df, x_test, y_test)\n",
    "recall_res = recall_func(mf_dr_df, x_test, y_test)\n",
    "\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_dr_df = MF_DR_JL_DF(num_user, num_item, num_feature, batch_size=128)\n",
    "mf_dr_df.to(device)\n",
    "mf_dr_df.fit(x_train, y_train_mask, e_train, d_train, feature_train, user_W, item_H, y_ips, lr=0.03, lamb=3e-5, lambv=0.01, tol=1e-4)\n",
    "test_pred = mf_dr_df.predict(x_test)\n",
    "mse = mse_func(y_test, test_pred)\n",
    "auc = roc_auc_score(y_test, test_pred)\n",
    "ndcg_res = ndcg_func(mf_dr_df, x_test, y_test)\n",
    "recall_res = recall_func(mf_dr_df, x_test, y_test)\n",
    "\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[162], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m mf_dr \u001b[38;5;241m=\u001b[39m MF_DR(num_user, num_item, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n\u001b[1;32m      5\u001b[0m mf_dr\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 6\u001b[0m mf_dr\u001b[38;5;241m.\u001b[39mfit(x_train, y_train_mask, y_ips, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.03\u001b[39m, lamb\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-6\u001b[39m,tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\n\u001b[1;32m      7\u001b[0m test_pred \u001b[38;5;241m=\u001b[39m mf_dr\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[1;32m      8\u001b[0m mse \u001b[38;5;241m=\u001b[39m mse_func(y_test, test_pred)\n",
      "File \u001b[0;32m~/Desktop/articles/delay_implicit/real-world/baselines.py:903\u001b[0m, in \u001b[0;36mMF_DR.fit\u001b[0;34m(self, x, y, y_ips, num_epoch, batch_size, lr, lamb, tol, G, verbose)\u001b[0m\n\u001b[1;32m    901\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    902\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m--> 903\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    905\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m xent_loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    907\u001b[0m relative_loss_div \u001b[38;5;241m=\u001b[39m (last_loss\u001b[38;5;241m-\u001b[39mepoch_loss)\u001b[38;5;241m/\u001b[39m(last_loss\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1e-10\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m             )\n\u001b[0;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/adam.py:168\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    157\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    159\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    160\u001b[0m         group,\n\u001b[1;32m    161\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    166\u001b[0m         state_steps)\n\u001b[0;32m--> 168\u001b[0m     adam(\n\u001b[1;32m    169\u001b[0m         params_with_grad,\n\u001b[1;32m    170\u001b[0m         grads,\n\u001b[1;32m    171\u001b[0m         exp_avgs,\n\u001b[1;32m    172\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    173\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    174\u001b[0m         state_steps,\n\u001b[1;32m    175\u001b[0m         amsgrad\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamsgrad\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    176\u001b[0m         has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[1;32m    177\u001b[0m         beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[1;32m    178\u001b[0m         beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[1;32m    179\u001b[0m         lr\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    180\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    181\u001b[0m         eps\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    182\u001b[0m         maximize\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    183\u001b[0m         foreach\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforeach\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    184\u001b[0m         capturable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    185\u001b[0m         differentiable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    186\u001b[0m         fused\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    187\u001b[0m         grad_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    188\u001b[0m         found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    189\u001b[0m     )\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/adam.py:318\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 318\u001b[0m func(params,\n\u001b[1;32m    319\u001b[0m      grads,\n\u001b[1;32m    320\u001b[0m      exp_avgs,\n\u001b[1;32m    321\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    322\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    323\u001b[0m      state_steps,\n\u001b[1;32m    324\u001b[0m      amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[1;32m    325\u001b[0m      has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[1;32m    326\u001b[0m      beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[1;32m    327\u001b[0m      beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[1;32m    328\u001b[0m      lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[1;32m    329\u001b[0m      weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[1;32m    330\u001b[0m      eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m    331\u001b[0m      maximize\u001b[38;5;241m=\u001b[39mmaximize,\n\u001b[1;32m    332\u001b[0m      capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[1;32m    333\u001b[0m      differentiable\u001b[38;5;241m=\u001b[39mdifferentiable,\n\u001b[1;32m    334\u001b[0m      grad_scale\u001b[38;5;241m=\u001b[39mgrad_scale,\n\u001b[1;32m    335\u001b[0m      found_inf\u001b[38;5;241m=\u001b[39mfound_inf)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/adam.py:441\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    439\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    443\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for DR\n",
    "mf_dr_acc = []\n",
    "for repeat in np.arange(10):\n",
    "    mf_dr = MF_DR(num_user, num_item, batch_size=128)\n",
    "    mf_dr.to(device)\n",
    "    mf_dr.fit(x_train, y_train_mask, y_ips, lr=0.03, lamb=5e-6,tol=1e-5)\n",
    "    test_pred = mf_dr.predict(x_test)\n",
    "    mse = mse_func(y_test, test_pred)\n",
    "    auc = roc_auc_score(y_test, test_pred)\n",
    "    ndcg_res = ndcg_func(mf_dr, x_test, y_test)\n",
    "    recall_res = recall_func(mf_dr, x_test, y_test)\n",
    "\n",
    "    print(auc)\n",
    "\n",
    "    mf_dr_acc.append([ mse, auc, np.mean(ndcg_res[\"ndcg_5\"]), np.mean(ndcg_res['ndcg_10']), np.mean(recall_res['recall_5']), np.mean(recall_res['recall_10'])   ])\n",
    "\n",
    "mf_dr_acc = np.array(mf_dr_acc)\n",
    "mf_dr_mean = mf_dr_acc.mean(0)\n",
    "mf_dr_sd = mf_dr_acc.std(0)\n",
    "\n",
    "print(\"[MF_DR] test auc:\", mf_dr_mean[1], ' sd: ', mf_dr_sd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
